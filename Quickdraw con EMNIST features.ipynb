{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quickdraw con EMNIST features\n",
    "\n",
    "En esta notebook tomé 5 clases de la base de datos de quickdraw: apple, smiley face, rabbit, bed, sun y pencil. Después dividí la red en dos partes, la parte de feature layers y la parte de clasification. Copié los pesos de la red entrenada con la base de datos de EMNIST, dicha red tenia la misma arquitectura. Posteriormente reentrené la red para obtener los pesos de las últimas capas (las de clasificación), y obtuve una predicción del 97.38%, lo cual es satisfactorio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import *\n",
    "from keras.callbacks import *\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import pandas as pd\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "#import cv2\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import*\n",
    "from module import printim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple=np.load('apple.npy')\n",
    "smiley_face=np.load('smiley_face.npy')\n",
    "rabbit=np.load('rabbit.npy')\n",
    "pencil=np.load('pencil.npy')\n",
    "bed=np.load('bed.npy')\n",
    "num_classes=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print(apple[0].reshape(28,28))\n",
    "plt.imshow(pencil[0].reshape(28,28),cmap='gray')\n",
    "plt.show()\n",
    "imsave('pencil.png',pencil[0].reshape(28,28),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_EMNIST=load_model('modelo_EMNIST_ok.h5')\n",
    "num_classes=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 1,199,237\n",
      "Trainable params: 1,180,421\n",
      "Non-trainable params: 18,816\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m_model=Sequential()\n",
    "feature_layers = [\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape = (28,28,1)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Dropout(0.25),\n",
    "    Flatten(),\n",
    "]\n",
    "classification_layers = [\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "]\n",
    "for l in feature_layers:\n",
    "    l.trainable = False\n",
    "m_model=Sequential(feature_layers+classification_layers)\n",
    "m_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights= [layer.get_weights() for layer in model_EMNIST.layers]\n",
    "for i in np.arange(0,len(feature_layers),1):\n",
    "        m_model.layers[i].set_weights(weights[i])\n",
    "m_model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 100000 samples, validate on 30000 samples\n",
      "Epoch 1/25\n",
      "100000/100000 [==============================] - 128s 1ms/step - loss: 0.2076 - acc: 0.9351 - val_loss: 0.1327 - val_acc: 0.9584\n",
      "Epoch 2/25\n",
      "100000/100000 [==============================] - 131s 1ms/step - loss: 0.1448 - acc: 0.9555 - val_loss: 0.1133 - val_acc: 0.9657\n",
      "Epoch 3/25\n",
      "100000/100000 [==============================] - 140s 1ms/step - loss: 0.1232 - acc: 0.9619 - val_loss: 0.1024 - val_acc: 0.9685\n",
      "Epoch 4/25\n",
      "100000/100000 [==============================] - 132s 1ms/step - loss: 0.1095 - acc: 0.9659 - val_loss: 0.1004 - val_acc: 0.9694\n",
      "Epoch 5/25\n",
      "100000/100000 [==============================] - 132s 1ms/step - loss: 0.1009 - acc: 0.9684 - val_loss: 0.1003 - val_acc: 0.9702\n",
      "Epoch 6/25\n",
      "100000/100000 [==============================] - 131s 1ms/step - loss: 0.0935 - acc: 0.9699 - val_loss: 0.0947 - val_acc: 0.9715\n",
      "Epoch 7/25\n",
      "100000/100000 [==============================] - 136s 1ms/step - loss: 0.0880 - acc: 0.9717 - val_loss: 0.0945 - val_acc: 0.9713\n",
      "Epoch 8/25\n",
      "100000/100000 [==============================] - 128s 1ms/step - loss: 0.0827 - acc: 0.9734 - val_loss: 0.0928 - val_acc: 0.9715\n",
      "Epoch 9/25\n",
      "100000/100000 [==============================] - 139s 1ms/step - loss: 0.0802 - acc: 0.9745 - val_loss: 0.0902 - val_acc: 0.9727\n",
      "Epoch 10/25\n",
      "100000/100000 [==============================] - 131s 1ms/step - loss: 0.0754 - acc: 0.9754 - val_loss: 0.0922 - val_acc: 0.9725\n",
      "Epoch 11/25\n",
      "100000/100000 [==============================] - 136s 1ms/step - loss: 0.0729 - acc: 0.9766 - val_loss: 0.0901 - val_acc: 0.9731\n",
      "Epoch 12/25\n",
      "100000/100000 [==============================] - 138s 1ms/step - loss: 0.0693 - acc: 0.9779 - val_loss: 0.0909 - val_acc: 0.9731\n",
      "Epoch 13/25\n",
      "100000/100000 [==============================] - 133s 1ms/step - loss: 0.0664 - acc: 0.9784 - val_loss: 0.0920 - val_acc: 0.9724\n",
      "Epoch 14/25\n",
      "100000/100000 [==============================] - 129s 1ms/step - loss: 0.0643 - acc: 0.9787 - val_loss: 0.0945 - val_acc: 0.9730\n",
      "Epoch 15/25\n",
      "100000/100000 [==============================] - 155s 2ms/step - loss: 0.0602 - acc: 0.9801 - val_loss: 0.0917 - val_acc: 0.9728\n",
      "Epoch 16/25\n",
      "100000/100000 [==============================] - 146s 1ms/step - loss: 0.0588 - acc: 0.9804 - val_loss: 0.0937 - val_acc: 0.9737\n",
      "Epoch 17/25\n",
      "100000/100000 [==============================] - 160s 2ms/step - loss: 0.0578 - acc: 0.9809 - val_loss: 0.0935 - val_acc: 0.9740\n",
      "Epoch 18/25\n",
      "100000/100000 [==============================] - 148s 1ms/step - loss: 0.0554 - acc: 0.9817 - val_loss: 0.0974 - val_acc: 0.9734\n",
      "Epoch 19/25\n",
      "100000/100000 [==============================] - 151s 2ms/step - loss: 0.0544 - acc: 0.9815 - val_loss: 0.0929 - val_acc: 0.9735\n",
      "Epoch 20/25\n",
      "100000/100000 [==============================] - 147s 1ms/step - loss: 0.0532 - acc: 0.9823 - val_loss: 0.0963 - val_acc: 0.9741\n",
      "Epoch 21/25\n",
      "100000/100000 [==============================] - 141s 1ms/step - loss: 0.0500 - acc: 0.9830 - val_loss: 0.0988 - val_acc: 0.9729\n",
      "Epoch 22/25\n",
      "100000/100000 [==============================] - 157s 2ms/step - loss: 0.0494 - acc: 0.9832 - val_loss: 0.0981 - val_acc: 0.9740\n",
      "Epoch 23/25\n",
      "100000/100000 [==============================] - 142s 1ms/step - loss: 0.0473 - acc: 0.9839 - val_loss: 0.0980 - val_acc: 0.9740\n",
      "Epoch 24/25\n",
      "100000/100000 [==============================] - 140s 1ms/step - loss: 0.0481 - acc: 0.9839 - val_loss: 0.0992 - val_acc: 0.9738\n",
      "Epoch 25/25\n",
      "100000/100000 [==============================] - 128s 1ms/step - loss: 0.0463 - acc: 0.9840 - val_loss: 0.1029 - val_acc: 0.9731\n"
     ]
    }
   ],
   "source": [
    "muestras=20000\n",
    "x_train=np.vstack([apple[0:muestras,:],pencil[0:muestras,:],rabbit[0:muestras,:],smiley_face[0:muestras,:],bed[0:muestras,:]])\n",
    "#print(x_train.shape)\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32')/255\n",
    "y_train=np.array([np.zeros(muestras),np.ones(muestras),np.ones(muestras)*2,np.ones(muestras)*3,np.ones(muestras)*4])\n",
    "y_train=y_train.reshape(muestras*5)\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "x_test=np.vstack([apple[muestras:int(muestras+muestras*0.3),:],pencil[muestras:int(muestras+muestras*0.3),:],rabbit[muestras:int(muestras+muestras*0.3),:],smiley_face[muestras:int(muestras+muestras*0.3),:],bed[muestras:int(muestras+muestras*0.3),:]])\n",
    "#print(x_train.shape)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype('float32')/255\n",
    "y_test=np.array([np.zeros(int(muestras*0.3)),np.ones(int(muestras*0.3)),np.ones(int(muestras*0.3))*2,np.ones(int(muestras*0.3))*3,np.ones(int(muestras*0.3))*4])\n",
    "y_test=y_test.reshape(int(muestras*0.3)*5)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "hist=m_model.fit(x_train, y_train, batch_size=128*4, epochs=25, verbose=1,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('Quickdraw_with_EMNIST.json', 'w') as f:\n",
    "    json.dump(hist.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 1,199,237\n",
      "Trainable params: 1,199,237\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 100000 samples, validate on 30000 samples\n",
      "Epoch 1/25\n",
      "100000/100000 [==============================] - 316s 3ms/step - loss: 0.3897 - acc: 0.8717 - val_loss: 0.1821 - val_acc: 0.9411\n",
      "Epoch 2/25\n",
      "100000/100000 [==============================] - 314s 3ms/step - loss: 0.1819 - acc: 0.9438 - val_loss: 0.1380 - val_acc: 0.9577\n",
      "Epoch 3/25\n",
      "100000/100000 [==============================] - 314s 3ms/step - loss: 0.1504 - acc: 0.9541 - val_loss: 0.1233 - val_acc: 0.9616\n",
      "Epoch 4/25\n",
      "100000/100000 [==============================] - 331s 3ms/step - loss: 0.1306 - acc: 0.9594 - val_loss: 0.1171 - val_acc: 0.9648\n",
      "Epoch 5/25\n",
      "100000/100000 [==============================] - 336s 3ms/step - loss: 0.1200 - acc: 0.9628 - val_loss: 0.1096 - val_acc: 0.9669\n",
      "Epoch 6/25\n",
      "100000/100000 [==============================] - 315s 3ms/step - loss: 0.1083 - acc: 0.9664 - val_loss: 0.0982 - val_acc: 0.9691\n",
      "Epoch 7/25\n",
      "100000/100000 [==============================] - 314s 3ms/step - loss: 0.1019 - acc: 0.9687 - val_loss: 0.1015 - val_acc: 0.9693\n",
      "Epoch 8/25\n",
      "100000/100000 [==============================] - 313s 3ms/step - loss: 0.0928 - acc: 0.9706 - val_loss: 0.0912 - val_acc: 0.9714\n",
      "Epoch 9/25\n",
      "100000/100000 [==============================] - 313s 3ms/step - loss: 0.0880 - acc: 0.9718 - val_loss: 0.0989 - val_acc: 0.9708\n",
      "Epoch 10/25\n",
      "100000/100000 [==============================] - 308s 3ms/step - loss: 0.0835 - acc: 0.9732 - val_loss: 0.0904 - val_acc: 0.9727\n",
      "Epoch 11/25\n",
      "100000/100000 [==============================] - 316s 3ms/step - loss: 0.0786 - acc: 0.9752 - val_loss: 0.0868 - val_acc: 0.9734\n",
      "Epoch 12/25\n",
      "100000/100000 [==============================] - 318s 3ms/step - loss: 0.0731 - acc: 0.9765 - val_loss: 0.0888 - val_acc: 0.9736\n",
      "Epoch 13/25\n",
      "100000/100000 [==============================] - 318s 3ms/step - loss: 0.0695 - acc: 0.9776 - val_loss: 0.0878 - val_acc: 0.9735\n",
      "Epoch 14/25\n",
      "100000/100000 [==============================] - 320s 3ms/step - loss: 0.0663 - acc: 0.9783 - val_loss: 0.0995 - val_acc: 0.9702\n",
      "Epoch 15/25\n",
      "100000/100000 [==============================] - 309s 3ms/step - loss: 0.0620 - acc: 0.9797 - val_loss: 0.0927 - val_acc: 0.9733\n",
      "Epoch 16/25\n",
      "100000/100000 [==============================] - 305s 3ms/step - loss: 0.0585 - acc: 0.9808 - val_loss: 0.0854 - val_acc: 0.9750\n",
      "Epoch 17/25\n",
      "100000/100000 [==============================] - 302s 3ms/step - loss: 0.0566 - acc: 0.9810 - val_loss: 0.0954 - val_acc: 0.9744\n",
      "Epoch 18/25\n",
      "100000/100000 [==============================] - 301s 3ms/step - loss: 0.0538 - acc: 0.9817 - val_loss: 0.0881 - val_acc: 0.9748\n",
      "Epoch 19/25\n",
      "100000/100000 [==============================] - 300s 3ms/step - loss: 0.0523 - acc: 0.9824 - val_loss: 0.0965 - val_acc: 0.9747\n",
      "Epoch 20/25\n",
      "100000/100000 [==============================] - 300s 3ms/step - loss: 0.0472 - acc: 0.9841 - val_loss: 0.1031 - val_acc: 0.9709\n",
      "Epoch 21/25\n",
      "100000/100000 [==============================] - 300s 3ms/step - loss: 0.0464 - acc: 0.9842 - val_loss: 0.0960 - val_acc: 0.9754\n",
      "Epoch 22/25\n",
      "100000/100000 [==============================] - 300s 3ms/step - loss: 0.0446 - acc: 0.9848 - val_loss: 0.0999 - val_acc: 0.9758\n",
      "Epoch 23/25\n",
      "100000/100000 [==============================] - 299s 3ms/step - loss: 0.0440 - acc: 0.9849 - val_loss: 0.1025 - val_acc: 0.9748\n",
      "Epoch 24/25\n",
      "100000/100000 [==============================] - 299s 3ms/step - loss: 0.0417 - acc: 0.9854 - val_loss: 0.0955 - val_acc: 0.9747\n",
      "Epoch 25/25\n",
      "100000/100000 [==============================] - 298s 3ms/step - loss: 0.0398 - acc: 0.9860 - val_loss: 0.0949 - val_acc: 0.9751\n"
     ]
    }
   ],
   "source": [
    "model_EMNIST=load_model('modelo_EMNIST_ok.h5')\n",
    "num_classes=5\n",
    "m_model=Sequential()\n",
    "feature_layers = [\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape = (28,28,1)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Dropout(0.25),\n",
    "    Flatten(),\n",
    "]\n",
    "classification_layers = [\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "]\n",
    "for l in feature_layers:\n",
    "    l.trainable = True\n",
    "m_model=Sequential(feature_layers+classification_layers)\n",
    "m_model.summary()\n",
    "muestras=20000\n",
    "x_train=np.vstack([apple[0:muestras,:],pencil[0:muestras,:],rabbit[0:muestras,:],smiley_face[0:muestras,:],bed[0:muestras,:]])\n",
    "#print(x_train.shape)\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32')/255\n",
    "y_train=np.array([np.zeros(muestras),np.ones(muestras),np.ones(muestras)*2,np.ones(muestras)*3,np.ones(muestras)*4])\n",
    "y_train=y_train.reshape(muestras*5)\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "x_test=np.vstack([apple[muestras:int(muestras+muestras*0.3),:],pencil[muestras:int(muestras+muestras*0.3),:],rabbit[muestras:int(muestras+muestras*0.3),:],smiley_face[muestras:int(muestras+muestras*0.3),:],bed[muestras:int(muestras+muestras*0.3),:]])\n",
    "#print(x_train.shape)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype('float32')/255\n",
    "y_test=np.array([np.zeros(int(muestras*0.3)),np.ones(int(muestras*0.3)),np.ones(int(muestras*0.3))*2,np.ones(int(muestras*0.3))*3,np.ones(int(muestras*0.3))*4])\n",
    "y_test=y_test.reshape(int(muestras*0.3)*5)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "m_model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
    "hist=m_model.fit(x_train, y_train, batch_size=128*4, epochs=25, verbose=1,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('Quickdraw.json', 'w') as f:\n",
    "    json.dump(hist.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
